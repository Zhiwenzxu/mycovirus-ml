{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5460\n",
      "1641\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def parse_fasta(file):\n",
    "    genomes = {}\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.replace('\\n', '')\n",
    "            if line.startswith(\">\"):\n",
    "                curr = line\n",
    "                genomes[curr] = ''\n",
    "                continue\n",
    "            genomes[curr] = genomes[curr] + line\n",
    "    return genomes\n",
    "\n",
    "B_fa = 'hiv_subtypeB.fasta'\n",
    "C_fa = 'hiv_subtypeC.fasta'\n",
    "typeB = parse_fasta(B_fa)\n",
    "typeC = parse_fasta(C_fa)\n",
    "print(len(typeB))\n",
    "print(len(typeC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5460\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "typeB = [typeB[a] for a in typeB]\n",
    "random.shuffle(typeB)\n",
    "print(len(typeB))\n",
    "typeB = typeB[:2000]\n",
    "print(len(typeB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3641\n"
     ]
    }
   ],
   "source": [
    "all_sequences = typeB + [typeC[a] for a in typeC]\n",
    "print(len(all_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3641"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array([0 for i in typeB] + [1 for i in typeC])\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14825"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(a) for a in all_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer='char')\n",
    "X = count_vect.fit_transform(all_sequences)\n",
    "chars = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'g', 'h', 'k', 'm', 'n', 'r', 's', 't', 'v', 'w', 'y']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-gram features generation\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "count_vect = CountVectorizer(analyzer='char',ngram_range=(5,6))\n",
    "X = count_vect.fit_transform(all_sequences)\n",
    "chars = count_vect.get_feature_names()\n",
    "five_gram = X.toarray()\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(five_gram) #Enable inverse-document-frequency reweighting\n",
    "five_gram_tf = tf_transformer.transform(five_gram)\n",
    "five_gram_tf = five_gram_tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3641, 25371)\n"
     ]
    }
   ],
   "source": [
    "print(five_gram_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2548, 25371)\n",
      "(2548,)\n",
      "(1093, 25371)\n",
      "(1093,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(five_gram_tf, labels, shuffle=True, test_size=0.3, random_state=46)\n",
    "#X_train = X_train[:,:,np.newaxis]\n",
    "#X_test = X_test[:,:,np.newaxis]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D,MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-MER (3-5) WITH CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=8,kernel_size=5,padding='same',activation=None))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=16,kernel_size=5,padding='same',activation=None))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=32,kernel_size=5,padding='same',activation=None))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=64,kernel_size=5,padding='same',activation=None))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=128,kernel_size=5,padding='same',activation=None))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1,activation=None))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deep_cnn()\n",
    "metrics = ['acc']\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.fit(X_train,y_train,batch_size=64,epochs=20,validation_split=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.predict(X_test[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-MER (4-6) WITH SIMPLE DENSE LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_MLP():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2048,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1,activation=None))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_MLP()\n",
    "metrics = ['acc']\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2038 samples, validate on 510 samples\n",
      "Epoch 1/20\n",
      "2038/2038 [==============================] - 15s 7ms/sample - loss: 0.7378 - acc: 0.5785 - val_loss: 0.6644 - val_acc: 0.5529\n",
      "Epoch 2/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.2311 - acc: 0.9279 - val_loss: 0.6358 - val_acc: 0.5529\n",
      "Epoch 3/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0597 - acc: 0.9946 - val_loss: 0.7155 - val_acc: 0.5529\n",
      "Epoch 4/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0366 - acc: 0.9990 - val_loss: 0.5906 - val_acc: 0.5529\n",
      "Epoch 5/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0256 - acc: 0.9995 - val_loss: 0.3485 - val_acc: 0.7137\n",
      "Epoch 6/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0193 - acc: 0.9995 - val_loss: 0.2033 - val_acc: 0.9882\n",
      "Epoch 7/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0132 - acc: 0.9995 - val_loss: 0.1013 - val_acc: 0.9980\n",
      "Epoch 8/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0142 - acc: 0.9985 - val_loss: 0.0644 - val_acc: 0.9980\n",
      "Epoch 9/20\n",
      "2038/2038 [==============================] - 11s 5ms/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0337 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "2038/2038 [==============================] - 11s 5ms/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "2038/2038 [==============================] - 11s 5ms/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0076 - acc: 0.9985 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "2038/2038 [==============================] - 11s 5ms/sample - loss: 0.0062 - acc: 0.9990 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0048 - acc: 0.9995 - val_loss: 6.6101e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0044 - acc: 0.9990 - val_loss: 3.7756e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 2.8420e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "2038/2038 [==============================] - 10s 5ms/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 2.1441e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f87f6a7d48>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=64,epochs=20,validation_split=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9975812e-01],\n",
       "       [9.9980348e-01],\n",
       "       [2.0113587e-04],\n",
       "       [9.9988329e-01],\n",
       "       [9.9971592e-01],\n",
       "       [1.9609928e-04],\n",
       "       [1.9085407e-04],\n",
       "       [9.9979329e-01],\n",
       "       [1.8319488e-04],\n",
       "       [1.7747283e-04],\n",
       "       [1.7100573e-04],\n",
       "       [9.9984157e-01],\n",
       "       [2.2399426e-04],\n",
       "       [1.5261769e-04],\n",
       "       [9.9984813e-01],\n",
       "       [9.9942172e-01],\n",
       "       [1.8125772e-04],\n",
       "       [9.9978197e-01],\n",
       "       [9.9974126e-01],\n",
       "       [9.9978924e-01],\n",
       "       [9.9971879e-01],\n",
       "       [9.9978888e-01],\n",
       "       [9.9981296e-01],\n",
       "       [9.9984956e-01],\n",
       "       [9.9981511e-01],\n",
       "       [1.6427040e-04],\n",
       "       [2.0429492e-04],\n",
       "       [9.9980628e-01],\n",
       "       [9.9964178e-01],\n",
       "       [2.1326542e-04],\n",
       "       [9.9967927e-01],\n",
       "       [9.9979997e-01],\n",
       "       [9.9983025e-01],\n",
       "       [9.9979722e-01],\n",
       "       [2.0909309e-04],\n",
       "       [9.9976450e-01],\n",
       "       [9.9970889e-01],\n",
       "       [1.8906593e-04],\n",
       "       [1.7315149e-04],\n",
       "       [1.9955635e-04],\n",
       "       [1.8531084e-04],\n",
       "       [1.6286969e-04],\n",
       "       [9.9981034e-01],\n",
       "       [2.1341443e-04],\n",
       "       [9.9984193e-01],\n",
       "       [1.4948845e-04],\n",
       "       [9.9970734e-01],\n",
       "       [9.9976790e-01],\n",
       "       [1.7554125e-04],\n",
       "       [9.9974853e-01]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp k-mer test loss, test acc: [0.00021441213504936588, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#score_kmer = model.evaluate(X_test, y_test)\n",
    "print('mlp k-mer test loss, test acc:', score_kmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset metrics before saving so that loaded model has same state,\n",
    "# since metric states are not preserved by Model.save_weights\n",
    "model.reset_metrics()\n",
    "model.save('saved_models/kmer_mlp_hiv.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASCII ENCODING WITH CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_with_ascii(sequences):\n",
    "    length = max([len(s) for s in sequences])\n",
    "    result = np.zeros((len(sequences), length))\n",
    "    print(result.shape)\n",
    "    for i in range(len(sequences)):\n",
    "        for j in range(length):\n",
    "            c = 0\n",
    "            if j < len(sequences[i]):\n",
    "                c = ord(sequences[i][j])\n",
    "            result[i, j] = c\n",
    "    print(\"hello\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3641, 14825)\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "ascii_en = encode_with_ascii(all_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2548, 14825, 1)\n",
      "(2548,)\n",
      "(1093, 14825, 1)\n",
      "(1093,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ascii_en, labels, shuffle=True, test_size=0.3, random_state=46)\n",
    "X_train = X_train[:,:,np.newaxis]\n",
    "X_test = X_test[:,:,np.newaxis]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2038 samples, validate on 510 samples\n",
      "Epoch 1/20\n",
      "2038/2038 [==============================] - 71s 35ms/sample - loss: 0.7762 - acc: 0.5751 - val_loss: 0.6929 - val_acc: 0.5529\n",
      "Epoch 2/20\n",
      "2038/2038 [==============================] - 64s 32ms/sample - loss: 0.5309 - acc: 0.7399 - val_loss: 0.8128 - val_acc: 0.5529\n",
      "Epoch 3/20\n",
      "2038/2038 [==============================] - 65s 32ms/sample - loss: 0.2937 - acc: 0.8847 - val_loss: 1.2976 - val_acc: 0.5529\n",
      "Epoch 4/20\n",
      "2038/2038 [==============================] - 65s 32ms/sample - loss: 0.1243 - acc: 0.9632 - val_loss: 1.6840 - val_acc: 0.5529\n",
      "Epoch 5/20\n",
      "2038/2038 [==============================] - 64s 32ms/sample - loss: 0.0736 - acc: 0.9799 - val_loss: 2.0227 - val_acc: 0.5529\n",
      "Epoch 6/20\n",
      "2038/2038 [==============================] - 64s 32ms/sample - loss: 0.0460 - acc: 0.9921 - val_loss: 2.1619 - val_acc: 0.5529\n",
      "Epoch 7/20\n",
      "2038/2038 [==============================] - 64s 32ms/sample - loss: 0.0308 - acc: 0.9961 - val_loss: 2.4745 - val_acc: 0.5529\n",
      "Epoch 8/20\n",
      "2038/2038 [==============================] - 66s 32ms/sample - loss: 0.0260 - acc: 0.9975 - val_loss: 2.4809 - val_acc: 0.5529\n",
      "Epoch 9/20\n",
      "2038/2038 [==============================] - 65s 32ms/sample - loss: 0.0189 - acc: 0.9975 - val_loss: 2.4295 - val_acc: 0.5529\n",
      "Epoch 10/20\n",
      "2038/2038 [==============================] - 65s 32ms/sample - loss: 0.0194 - acc: 0.9961 - val_loss: 2.2569 - val_acc: 0.5529\n",
      "Epoch 11/20\n",
      "2038/2038 [==============================] - 65s 32ms/sample - loss: 0.0202 - acc: 0.9966 - val_loss: 2.3194 - val_acc: 0.5529\n",
      "Epoch 12/20\n",
      "2038/2038 [==============================] - 65s 32ms/sample - loss: 0.0123 - acc: 0.9990 - val_loss: 0.0427 - val_acc: 0.9902\n",
      "Epoch 13/20\n",
      "2038/2038 [==============================] - 65s 32ms/sample - loss: 0.0129 - acc: 0.9980 - val_loss: 0.4322 - val_acc: 0.7941\n",
      "Epoch 14/20\n",
      "2038/2038 [==============================] - 65s 32ms/sample - loss: 0.0144 - acc: 0.9971 - val_loss: 1.6301 - val_acc: 0.5529\n",
      "Epoch 15/20\n",
      "2038/2038 [==============================] - 65s 32ms/sample - loss: 0.0195 - acc: 0.9961 - val_loss: 0.0104 - val_acc: 0.9980\n",
      "Epoch 16/20\n",
      "2038/2038 [==============================] - 66s 33ms/sample - loss: 0.0114 - acc: 0.9975 - val_loss: 0.0333 - val_acc: 0.9902\n",
      "Epoch 17/20\n",
      " 128/2038 [>.............................] - ETA: 1:00 - loss: 0.0157 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-527dceef9c44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = deep_cnn()\n",
    "metrics = ['acc']\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=metrics)\n",
    "model.fit(X_train,y_train,batch_size=64,epochs=20,validation_split=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.94860053e-01],\n",
       "       [9.67233658e-01],\n",
       "       [1.63704157e-04],\n",
       "       [9.97560978e-01],\n",
       "       [8.85849297e-01],\n",
       "       [1.13636255e-04],\n",
       "       [2.88695097e-04],\n",
       "       [9.94378328e-01],\n",
       "       [9.20593739e-05],\n",
       "       [1.32292509e-04],\n",
       "       [2.64167786e-04],\n",
       "       [9.98015344e-01],\n",
       "       [1.60038471e-04],\n",
       "       [1.02818012e-04],\n",
       "       [9.87549424e-01],\n",
       "       [9.93807197e-01],\n",
       "       [9.16421413e-05],\n",
       "       [9.48706508e-01],\n",
       "       [9.53589916e-01],\n",
       "       [9.77461934e-01],\n",
       "       [9.90941405e-01],\n",
       "       [9.97562289e-01],\n",
       "       [9.99549210e-01],\n",
       "       [9.99529362e-01],\n",
       "       [9.91274953e-01],\n",
       "       [1.28746033e-04],\n",
       "       [3.69071960e-03],\n",
       "       [9.97097790e-01],\n",
       "       [9.77784276e-01],\n",
       "       [1.71378255e-03],\n",
       "       [9.91498351e-01],\n",
       "       [9.94295478e-01],\n",
       "       [9.98548269e-01],\n",
       "       [9.69663560e-01],\n",
       "       [1.30146742e-04],\n",
       "       [8.61543894e-01],\n",
       "       [9.21850145e-01],\n",
       "       [9.33408737e-05],\n",
       "       [1.37031078e-04],\n",
       "       [1.48713589e-04],\n",
       "       [1.37060881e-04],\n",
       "       [8.93175602e-05],\n",
       "       [9.86835182e-01],\n",
       "       [1.87575817e-04],\n",
       "       [9.87280011e-01],\n",
       "       [7.50422478e-05],\n",
       "       [9.89108443e-01],\n",
       "       [2.91239619e-02],\n",
       "       [1.42872843e-04],\n",
       "       [9.97002065e-01]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss, test acc: [0.046434312636221865, 0.9853614]\n"
     ]
    }
   ],
   "source": [
    "#score_ascii = model.evaluate(X_test, y_test)\n",
    "print('test loss, test acc:', score_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset metrics before saving so that loaded model has same state,\n",
    "# since metric states are not preserved by Model.save_weights\n",
    "model.reset_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_models/ascii_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # put ascii code in between -1 and 1\n",
    "# for i in range(ascii_en.shape[0]):\n",
    "#     for j in range(ascii_en.shape[1]):\n",
    "#         if ascii_en[i,j] == 0:\n",
    "#             continue\n",
    "#         ascii_en[i, j] = (ascii_en[i, j]-(65+25/2))/(25/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(ascii_en, labels, shuffle=True, test_size=0.3, random_state=46)\n",
    "# X_train = X_train[:,:,np.newaxis]\n",
    "# X_test = X_test[:,:,np.newaxis]\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "# model = deep_cnn()\n",
    "# metrics = ['acc']\n",
    "# model.compile(optimizer='adam',loss='binary_crossentropy',metrics=metrics)\n",
    "# model.fit(X_train,y_train,batch_size=64,epochs=20,validation_split=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
